{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "!pip install SpeechRecognition"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REGT410ecMyH",
        "outputId": "e8816ca5-d73c-458e-b44b-f52f2004f59b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deepface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHPGWm8Fil9S",
        "outputId": "8acd0912-a7d1-40b4-b402-a9a565f037f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepface in /usr/local/lib/python3.11/dist-packages (0.0.93)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.0.1)\n",
            "Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.0.0)\n",
            "Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.0.17)\n",
            "Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.7.0)\n",
            "Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (23.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.0.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install moviepy SpeechRecognition pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LaI-e78Xzie",
        "outputId": "6286d426-d08d-4495-e8b1-4fe5b36ff054"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n8-mvlBVbpYo"
      },
      "outputs": [],
      "source": [
        "import cv2  # OpenCV\n",
        "import numpy as np\n",
        "from keras.models import load_model  # For CNN model\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "import pandas as pd\n",
        "from deepface import DeepFace\n",
        "import moviepy.editor as mp\n",
        "import speech_recognition as sr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Haar cascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Input video\n",
        "video_path = '/content/3.mp4' # <-- Replace with your video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Create folder to save face images\n",
        "output_folder = 'detected_faces'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process every 10th frame (to reduce load)\n",
        "    if frame_count % 10 == 0:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces\n",
        "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "        for i, (x, y, w, h) in enumerate(faces):\n",
        "            face_img = frame[y:y+h, x:x+w]\n",
        "            face_filename = os.path.join(output_folder, f'face_{frame_count}_{i}.jpg')\n",
        "            cv2.imwrite(face_filename, face_img)\n",
        "            saved_count += 1\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Done! Total faces saved: {saved_count}\")\n"
      ],
      "metadata": {
        "id": "0SA9YYA5buUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a3d956-1c83-4d5d-a222-e4fe2cc9a2eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! Total faces saved: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import pandas as pd\n",
        "# from deepface import DeepFace\n",
        "\n",
        "# Folder with face images\n",
        "face_folder = 'detected_faces'\n",
        "\n",
        "# Loop through images\n",
        "for img_file in os.listdir(face_folder):\n",
        "    if img_file.endswith('.jpg'):\n",
        "        img_path = os.path.join(face_folder, img_file)\n",
        "        try:\n",
        "            # Read image\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Analyze emotion\n",
        "            result = DeepFace.analyze(img, actions=['emotion'], enforce_detection=False)\n",
        "\n",
        "            # Get predicted emotion\n",
        "            emotion = result[0]['dominant_emotion']\n",
        "            print(f\"{img_file}: {emotion}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing {img_file}: {e}\")\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Inside the loop:\n",
        "        results.append({'Image': img_file, 'Emotion': emotion})\n",
        "\n",
        "# After the loop:\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('emotion_results.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "sVhlGYDFipdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe05b0c-12d5-4fd3-aafc-eb1db08bc11d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face_310_1.jpg: neutral\n",
            "face_820_0.jpg: fear\n",
            "face_630_0.jpg: angry\n",
            "face_840_0.jpg: angry\n",
            "face_640_0.jpg: angry\n",
            "face_600_0.jpg: angry\n",
            "face_50_0.jpg: neutral\n",
            "face_260_0.jpg: angry\n",
            "face_580_0.jpg: angry\n",
            "face_0_0.jpg: angry\n",
            "face_20_0.jpg: neutral\n",
            "face_650_0.jpg: happy\n",
            "face_60_0.jpg: neutral\n",
            "face_420_0.jpg: sad\n",
            "face_430_0.jpg: neutral\n",
            "face_60_1.jpg: neutral\n",
            "face_360_0.jpg: happy\n",
            "face_850_0.jpg: angry\n",
            "face_40_0.jpg: neutral\n",
            "face_790_0.jpg: fear\n",
            "face_30_0.jpg: neutral\n",
            "face_440_0.jpg: angry\n",
            "face_800_0.jpg: fear\n",
            "face_530_0.jpg: angry\n",
            "face_930_0.jpg: fear\n",
            "face_250_0.jpg: angry\n",
            "face_930_1.jpg: neutral\n",
            "face_780_0.jpg: surprise\n",
            "face_590_0.jpg: surprise\n",
            "face_450_0.jpg: angry\n",
            "face_10_0.jpg: neutral\n",
            "face_680_0.jpg: angry\n",
            "face_560_0.jpg: sad\n",
            "face_370_0.jpg: neutral\n",
            "face_810_0.jpg: sad\n",
            "face_340_0.jpg: angry\n",
            "face_350_0.jpg: fear\n",
            "face_660_0.jpg: angry\n",
            "face_920_0.jpg: fear\n",
            "face_710_0.jpg: angry\n",
            "face_570_0.jpg: angry\n",
            "face_310_0.jpg: neutral\n",
            "face_550_0.jpg: angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import moviepy.editor as mp\n",
        "# import speech_recognition as sr\n",
        "\n",
        "# Extract audio from video\n",
        "video = mp.VideoFileClip(\"/content/3.mp4\")\n",
        "video.audio.write_audiofile(\"audio.wav\")\n",
        "\n",
        "# Convert audio to text\n",
        "recognizer = sr.Recognizer()\n",
        "with sr.AudioFile(\"audio.wav\") as source:\n",
        "    audio = recognizer.record(source)\n",
        "\n",
        "try:\n",
        "    text = recognizer.recognize_google(audio)\n",
        "    print(\"Transcribed text:\\n\", text)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Could not understand the audio.\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "train_texts = [\n",
        "    \"I am feeling very happy today\",\n",
        "    \"This is so sad and painful\",\n",
        "    \"I am extremely angry right now\",\n",
        "    \"What a wonderful day\",\n",
        "    \"I'm so scared of what might happen\",\n",
        "    \"Everything is boring and dull\",\n",
        "    \"I feel great and joyful\",\n",
        "    \"I can't stop crying\",\n",
        "    \"Why are you yelling at me!\",\n",
        "    \"I'm trembling with fear\",\n",
        "    \"Nothing excites me anymore\"\n",
        "]\n",
        "train_labels = ['happy', 'sad', 'angry', 'happy', 'fear', 'neutral', 'happy', 'sad', 'angry', 'fear', 'neutral']\n",
        "\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Train SVM\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, train_labels)\n",
        "\n",
        "# Use transcribed video text for prediction\n",
        "video_text = text  # From the earlier step\n",
        "X_test = vectorizer.transform([video_text])\n",
        "predicted_emotion = svm.predict(X_test)\n",
        "\n",
        "print(\"Predicted emotion from audio/text:\", predicted_emotion[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_NJ7NS5juAT",
        "outputId": "206442f9-961c-4959-f2e5-d3b00b3d98b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Transcribed text:\n",
            " how to System of a Down in 30 seconds drop C or C sharp tuning half steps thrush it up Groove hi grocery list lyrics death metal acoustic random go tree go\n",
            "Predicted emotion from audio/text: fear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from deepface import DeepFace\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "# Create folder to store frames\n",
        "os.makedirs(\"frames\", exist_ok=True)\n",
        "\n",
        "# Load video and extract frames\n",
        "# Changed video path to the correct one, assuming it's the same as before\n",
        "cap = cv2.VideoCapture(\"/content/3.mp4\")\n",
        "frame_rate = 30  # analyze one frame every 30 frames (~1 second if 30fps)\n",
        "frame_id = 0\n",
        "saved_frames = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frame_id % frame_rate == 0:\n",
        "        frame_path = f\"frames/frame_{frame_id}.jpg\"\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        saved_frames.append(frame_path)\n",
        "    frame_id += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Analyze each saved frame using DeepFace for emotion\n",
        "face_emotions = {}\n",
        "for path in saved_frames:\n",
        "    try:\n",
        "        result = DeepFace.analyze(img_path=path, actions=['emotion'], enforce_detection=False)\n",
        "        emotion = result[0]['dominant_emotion']\n",
        "        face_emotions[os.path.basename(path)] = emotion\n",
        "        print(f\"{path} → {emotion}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {path}: {e}\")\n",
        "\n",
        "# Count most common face emotion\n",
        "face_counts = Counter(face_emotions.values())\n",
        "\n",
        "# Check if face_counts is empty before accessing most_common\n",
        "if face_counts:\n",
        "    most_common_face_emotion, face_votes = face_counts.most_common(1)[0]\n",
        "    print(f\"Most common facial emotion: {most_common_face_emotion} ({face_votes} votes)\")\n",
        "else:\n",
        "    print(\"No faces detected or analyzed for emotions in the video.\")"
      ],
      "metadata": {
        "id": "443VUEFXkxvR",
        "outputId": "75f77522-1fb3-4eb4-f7f8-45a5fdf4a15f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frames/frame_0.jpg → angry\n",
            "frames/frame_30.jpg → neutral\n",
            "frames/frame_60.jpg → surprise\n",
            "frames/frame_90.jpg → fear\n",
            "frames/frame_120.jpg → angry\n",
            "frames/frame_150.jpg → angry\n",
            "frames/frame_180.jpg → sad\n",
            "frames/frame_210.jpg → sad\n",
            "frames/frame_240.jpg → angry\n",
            "frames/frame_270.jpg → sad\n",
            "frames/frame_300.jpg → happy\n",
            "frames/frame_330.jpg → neutral\n",
            "frames/frame_360.jpg → happy\n",
            "frames/frame_390.jpg → neutral\n",
            "frames/frame_420.jpg → sad\n",
            "frames/frame_450.jpg → angry\n",
            "frames/frame_480.jpg → angry\n",
            "frames/frame_510.jpg → surprise\n",
            "frames/frame_540.jpg → angry\n",
            "frames/frame_570.jpg → angry\n",
            "frames/frame_600.jpg → angry\n",
            "frames/frame_630.jpg → sad\n",
            "frames/frame_660.jpg → angry\n",
            "frames/frame_690.jpg → sad\n",
            "frames/frame_720.jpg → sad\n",
            "frames/frame_750.jpg → neutral\n",
            "frames/frame_780.jpg → surprise\n",
            "frames/frame_810.jpg → sad\n",
            "frames/frame_840.jpg → angry\n",
            "frames/frame_870.jpg → sad\n",
            "frames/frame_900.jpg → sad\n",
            "frames/frame_930.jpg → fear\n",
            "frames/frame_960.jpg → happy\n",
            "Most common facial emotion: angry (11 votes)\n",
            "frames/frame_0.jpg → angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1H4R02Kkzlu"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}